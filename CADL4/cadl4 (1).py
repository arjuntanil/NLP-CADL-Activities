# -*- coding: utf-8 -*-
"""CADL4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sacYZ_RQQ7BQTCNXpg3PT3cSaUO4yBA3
"""

!pip install gensim nltk scikit-learn pyLDAvis wordcloud matplotlib

# ==============================================================================
# 1. SETUP & DATA LOADING
# ==============================================================================
import nltk
from nltk.corpus import stopwords
import gensim
from gensim.utils import simple_preprocess
from gensim.models import LdaModel
from gensim.corpora import Dictionary
import pyLDAvis.gensim_models as gensimvis
import pyLDAvis
import warnings

# Suppress deprecation warnings for cleaner output
warnings.filterwarnings("ignore", category=DeprecationWarning)

# Download the NLTK stopwords list (only needs to be done once)
try:
    stopwords.words('english')
except LookupError:
    print("Downloading NLTK stopwords...")
    nltk.download('stopwords')

# Here is our new, smaller sample dataset
sample_documents = [
    "The solar system consists of the sun and the objects that orbit it.",
    "Mars is the fourth planet from the sun and is known as the Red Planet.",
    "The new AI model can generate realistic images from text descriptions.",
    "Machine learning is a subfield of artificial intelligence.",
    "The sun's energy is essential for life on Earth.",
    "Deep learning models require large amounts of data for training.",
    "Jupiter is the largest planet in our solar system.",
    "Natural language processing is a key area of AI research.",
    "The Apollo mission successfully landed humans on the moon, which orbits the Earth."
]

documents = sample_documents
print(f"Successfully loaded {len(documents)} custom documents.")


# ==============================================================================
# 2. PREPROCESSING THE TEXT
# ==============================================================================
print("\nPreprocessing text data...")
# Get the list of English stop words
stop_words = stopwords.words('english')

def preprocess_text(text):
    """
    Performs the following steps:
    1. Tokenizes the text (splits into words) and converts to lowercase.
    2. Removes stop words.
    3. Removes words that are 3 characters or less.
    """
    result = []
    for token in simple_preprocess(text):
        if token not in stop_words and len(token) > 3:
            result.append(token)
    return result

# Apply the preprocessing function to each document in the corpus
processed_docs = [preprocess_text(doc) for doc in documents]
print("Preprocessing complete.")
# Example of a preprocessed document
print("\n--- Example of a processed document ---")
print(processed_docs[0])


# ==============================================================================
# 3. APPLYING LDA
# ==============================================================================
# Create the dictionary and corpus needed for the LDA model

# Create a dictionary mapping words to unique IDs
id2word = Dictionary(processed_docs)

# *MODIFIED*: Since our dataset is small, we only filter words that appear less than 1 time.
id2word.filter_extremes(no_below=1, no_above=0.8)

# Convert the processed documents into a Bag-of-Words (BoW) corpus
corpus = [id2word.doc2bow(doc) for doc in processed_docs]

# --- Build the LDA Model ---
print("\nBuilding the LDA model...")

# *MODIFIED*: Set the number of topics to 3, matching our sample data's themes.
num_topics = 3

# The core LDA model training step
lda_model = LdaModel(corpus=corpus,
                     id2word=id2word,
                     num_topics=num_topics,
                     random_state=100,  # for reproducibility
                     passes=15)         # more passes can help on small data

print("LDA model training complete.")

# --- View the Topics ---
print("\n--- Top words for each of the {} identified topics ---".format(num_topics))
topics = lda_model.print_topics(num_words=5)
for i, topic in enumerate(topics):
    print(f"Topic {i+1}: {topic[1]}")


# ==============================================================================
# 4. VISUALIZE THE TOPICS
# ==============================================================================
print("\nPreparing visualization...")

# Enable the pyLDAvis visualization in the Jupyter Notebook
pyLDAvis.enable_notebook()

# Create the visualization data from the LDA model
vis_data = gensimvis.prepare(lda_model, corpus, id2word)

print("Displaying interactive topic model visualization below.")

# Display the visualization
vis_data